{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f80d1551",
      "metadata": {
        "id": "f80d1551"
      },
      "source": [
        "**Introduction**\n",
        "\n",
        "The aim of this exercise is to code a market-making algorithmic strategy to auto-response request for quotes (RfQs) in bonds in a multi-dealer to client platform. The model is based on the foundational Avellaneda and Stoikov model, with some adaptations to be used in the RfQ context. The core of the algorithm is a model that estimates the probability of winning the RfQ given the price we are quoting and the context of the operation.\n",
        "\n",
        "Delivery: Jupyter notebook (Python) with all the compulsory parts of the exercise and results\n",
        "\n",
        "\n",
        "***Description of the dataset***\n",
        "\n",
        "rfqs.csv:\n",
        "* date_time: date and time at which the quote is requested.\n",
        "* Instrument: the bond for which the customer has requested a price\n",
        "* client: client code (anonymized)\n",
        "* price: price quoted to the client by the bank\n",
        "* mid: market mid-price of the bond captured by the bank's system at the time of the operation\n",
        "* vol_MM: amount requested by the client (in millions of euros).\n",
        "* dv01: sensitivity of the bond to variations in its yield (a measure of risk of the bond)\n",
        "* num_dealers: number of banks from whom the client has requested a quote\n",
        "* side: 1 if it is buy -1 if it is sell (from the point of view of the bank, not the client)\n",
        "* won: 0 if the bank did not close the operation, 1 if it did."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8037e987",
      "metadata": {
        "id": "8037e987"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5e36017",
      "metadata": {
        "id": "d5e36017"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "# YOUR IMPORTS HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c068a13e",
      "metadata": {
        "id": "c068a13e"
      },
      "source": [
        "**Data reading and preparation**\n",
        "\n",
        "Read both datasets and perform an exploratory analysis of the data. Look at potential issues of missing data or outliers and clean it if you consider it necessary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7a6e6a4",
      "metadata": {
        "id": "a7a6e6a4"
      },
      "outputs": [],
      "source": [
        "rfq_df = pd.read_csv(\"rfqs.csv\", index_col = None)[['DateTime', 'instrument', 'client', 'price', 'mid',\n",
        "       'vol(MM)', 'dv01', 'num_dealers', 'side', 'won']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8db1c22a",
      "metadata": {
        "id": "8db1c22a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b9eaea59",
      "metadata": {
        "id": "b9eaea59"
      },
      "source": [
        "Clients are not really sensitive to the mid-price when they are buying or selling a product, since when they request a quote they typically have an estimation of it and therefore they are only sensitive to the \"spread\" we charge them on top of this mid-price as a compensation for the service of liquidity provision. The only exception is when they are requesting quotes for \"price discovery\", i.e. they are not interested to trade with any dealer, only to know which prices are quoted, but we will not consider this case in the exercise. To calculate the spread feature:\n",
        "\n",
        "1) Calculate the spread as the difference between the price and the mid, taking into account the side so that the spread should be mostly positive (there might be cases in which is negative, but a minority, for very aggressive quoting).\n",
        "\n",
        "2) Plot the histogram of the spreads and remove potential extreme cases (by business knowledge, we don't expect spreads higher than 10% of the mid price in absolute value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bb0605a",
      "metadata": {
        "id": "4bb0605a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "4f286b4e",
      "metadata": {
        "id": "4f286b4e"
      },
      "source": [
        "Create the following time features:\n",
        "* date column, using the DateTime column\n",
        "* time column, using the DateTime column\n",
        "* periodOfDay column, using the DateTime column to create a categorical feature that specifies the time of the day (morning, afternoon, evening, night)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "026895e2",
      "metadata": {
        "id": "026895e2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "69704097",
      "metadata": {
        "id": "69704097"
      },
      "source": [
        "**Probability of winning the RfQ**\n",
        "\n",
        "Let us implement a model that predicts the probability of winning the RfQ given our quoted spread. The target feature is the binary variable \"won\", which has values 1 if we win the RfQ and 0 if not. This is therefore a classification problem. In order to use this model in the Avellaneda - Stoikov market-making algorithm, we need to implement a predictive model with the following characteristics:\n",
        "\n",
        "1) the output is a probability, not the label\n",
        "\n",
        "2) the probability has to be a monotonic decreasing function of the quoted spread, since otherwise the result would not have and economic sense: if we quote a worse price to the client, the probability of winning the RfQ has to decrease necessarily!\n",
        "\n",
        "3) exploit other features of the dataset like client, instrument, volume, dv01, side or number of dealers or any derived feature from those.\n",
        "\n",
        "A possible model that fulfills these characteristics is the Logistic Regression, but you can choose any other model that respects 1-3. In the following, separate the dataset in training and test. If you are going to finetune hyperparameters, you can add a validation set or perform cross-validation over the training set. We recommend to analyze the following points when building the model:\n",
        "\n",
        "* For this exercise, limit the features to train the model to the following: 'instrument', 'client', 'vol(MM)', 'dv01','num_dealers', 'side', 'spread','periodOfDay' (and your target \"won\")\n",
        "\n",
        "* Pre-process your features before building your model: many models (not all, for instance trees) require that categorical features are one-hot encoded. The performance of many models also improve when normalizing the continuous features.\n",
        "\n",
        "* Use feature selection algorithms to reduce the input space before applying your model, unless you use a model that has feature selection embedded (e.g. in the Logistic Regression you can use an L1 Lasso regularization). Discuss which features are more relevant.\n",
        "\n",
        "* Even if your model enforces the monotonicity with respect to the spread, test graphically that this is the case\n",
        "\n",
        "* Be careful about imbalance in the dataset, how can you handle imbalance using your model?\n",
        "\n",
        "* Check that indeed the probability is a decreasing function of the spread\n",
        "\n",
        "* As quality metrics to test the model, use the following, and interpret the result:\n",
        "    * Accuracy. If the dataset is imbalanced, this is a potentially missleading metric. To see it, compare the results of your model with a baseline model where the majority class is always predicted. You can use sklearn's DummyClassifier for this\n",
        "    * Confusion matrix\n",
        "    * Area under the ROC curve\n",
        "    * Precision - Recall curve\n",
        "    * Reliability curve (also called calibration curve): divide the model output probability space in buckets of 10%, e.g. 0-10%, 10-20%, ..., 90-100%. Now for each bucket of output probabilities, compute the percentage of actual won operations (so-called \"hit-miss\"). If the model was perfect, you would obtain a straight line. Plot the curve, and also calculate the so-called Brier score, which is an average of squares of distances between the mid-points of the buckets and the hit-misses weighted by the number of observations per bucket. You can implement it yourself or use calibration_curve from sklearn.calibration\n",
        "    \n",
        "* Check how the performance depends on the amount of days used to train the model and select a good value to be used in the second part of the exercise\n",
        "\n",
        "[Hint] When doing the analysis, in principle, you should preserve the temporal ordering being a time-series data. However, once you condition on the features, the observations become relatively independent (you can check the autocorrelation for instance) and you can in principle take random subsets, which can help since the data is quite imbalanced and sometimes you might get subsets with only the majority class.\n",
        "\n",
        "[Tip] Once you have a pipeline of feature transformation, selection and model fit, use python's pipeline class to wrap it up together. You can use the following libraries:\n",
        "\n",
        "* sklearn.compose.ColumnTransformer: to transform separately your categorical and numerical features, for instance one-hot encoding the categorical and standarizing the numerical:\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "    \n",
        "* sklearn.preprocessing: it contains multiple pre-processors like OneHotEncoder to use in ColumnTransformer\n",
        "* sklearn.feature_selection.SelectFromModel: you can use it for feature selection using a model like Lasso for example\n",
        "* sklearn.pipeline.Pipeline: finally you put all together in a pipeline, for instance:\n",
        "\n",
        "pipeline = Pipeline([('preprocessor', preprocessor),\n",
        "                 ('feature_selector', selector),\n",
        "                 ('model', model)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0aef4ee",
      "metadata": {
        "id": "f0aef4ee"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "69f84cd8",
      "metadata": {
        "id": "69f84cd8"
      },
      "source": [
        "**Avellaneda-Stoikov market-making algorithm for RfQs**\n",
        "\n",
        "The Avellaneda-Stoikov model was originally developed for market-making in a Limit Order Book (LOB), although in practice is more suited to RfQ protocols, since it does not really model the LOB: for instance, it considers that any price is possible, ignoring the tick size. The optimal quoting (limit order price in a LOB, in our case the price quoted for the RfQ) has two components: one that considers the inventory risk, i.e. the risk of depreciation of our inventory until we find another investor willing to trade in the opposite direction; and the other that considers the price-sensitivity of the investor, via the probability of winning the RfQ model implemented above (in the case of a LOB, this is a filling probability or our limit order). For simplicity, we will use the first-order approximation from the original article, which simplifies the inventory risk term. The pricing formulae for the bid and ask half-spreads read:\n",
        "\n",
        "$\\delta_{b,i} = \\gamma \\sigma^2 (T-t)(q+\\frac{v_i}{2})+\\frac{1}{\\gamma v_i} \\log(1-\\gamma v_i\\frac{P(\\delta_{b,i})}{P'(\\delta_{b,i})})$\n",
        "\n",
        "$\\delta_{a,i} = \\gamma \\sigma^2 (T-t)(-q+\\frac{v_i}{2})+\\frac{1}{\\gamma v_i} \\log(1-\\gamma v_i\\frac{P(\\delta_{a,i})}{P'(\\delta_{a,i})})$\n",
        "\n",
        "Recall that the actual price quoted is the full-price:\n",
        "\n",
        "$p_{b,i} = p_{mid,i} - \\delta_{b,i}$\n",
        "\n",
        "$p_{a,i} = p_{mid,i} + \\delta_{a,i}$\n",
        "\n",
        "In these formulae, we have:\n",
        "\n",
        "* $\\delta_{b,i}, \\delta_{a,i}$: the half-spreads quoted for bid RfQs (the client wants to sell) and ask RfQs (the client wants to buy), respectively.\n",
        "* $\\gamma$: the risk-aversion of the trader or business operating the algorithm. It is an input to the algorithm.\n",
        "* $\\sigma$: the volatility (standard deviation of returns) of the instrument. It has to be computed at the same time-scale used in the model (e.g. if time is quoted in seconds, then it has to be a volatility per second)\n",
        "* $T$: the time-horizon in which we expect the market-maker to close any open position (e.g. inventory = 0). In this exercise we will consider a market-making operating during trading hours and closing all positions at market-close, to avoid overnight risk.\n",
        "* $t$: the current time at which we are quoting the RfQ. We will take as reference $t=0$ the opening of the market.\n",
        "* $v_i$: the volume of the RfQ, where $i$ is the index of the RfQ. We will use the units of the dataset in MM€.\n",
        "* $q$: the inventory held in the bond. We consider a separate inventory for each of the instruments. As a simplification, we don't consider correlations between instruments, which would require a multivariate version of the market-making formula. The inventory is $q=0$ at the beginning of the day. When a trade is closed, if the bank buys then $q \\rightarrow q + v_i$, and if it sells $q \\rightarrow q - v_i$. We allow negative inventories which imply a short position in the instrument.\n",
        "* $P()$: the predictive probability of winning the RfQ using our model. Although the formula only shows as input the half-spreads, it can also be fed with any other feature available at quotiong time.\n",
        "* $P'()$: the derivative of the probability of winning the RfQ with respect to the half-spread. For some models like the Logistic Regression it can be computed analytically, or you can use the utility function provided in the class.\n",
        "\n",
        "\n",
        "Write a class for the Avellaneda-Stoikov market-making algorithm by filling the interface (class) below. The algorithm is initialized with the algo parameters, in our case:\n",
        "* gamma, the risk aversion level\n",
        "* the number of days used for training the models, that you have calculated in the previous section (it has a default value just in case)\n",
        "* the time of closing the market as a datetime.time(). These quote-driven markets remain open longer than traditional stock exchanges, so we use 19:00:00 as a default value. Bear in mind that the algorithm works with a reference time normalized to 1, meaning that $t = 0$ at 00:00:00 and $t = 1$ at 23:59:59\n",
        "\n",
        "You need to fill the following methods (don't change the inputs!!):\n",
        "* _initPipeline: here you need you place your pipeline code from the previous section. The method has to be self-contained, i.e. all the info needed for initializing the pipeline must go into the method. Finally, store the pipeline in self.pipeline\n",
        "* _getVolatility: here you calculate the end of day volatility for each of the instruments, storing in self.volatility a dictionary key = instrument names, value = volatility (std of end of day prices). For eod prices just take the last value observed in the day for each instrument.\n",
        "* beforeMarketOpen: in this method you need to fit the pipeline, truncating the historical days to the number of days passed as an argument to the algorithm. This function is called every day before the market opens to prepare the algorithm for trading.\n",
        "* _pricingFormula: here you need to implement the Avellaneda - Stoikov pricing formula, taking into account if we have a bid or ask request and using the inputs passed to the function. Your function should address problematic cases like denominators close or equal to zero.\n",
        "* onTradeEvent: if the rfq is won, this function is triggered. You need to update the inventory and the cash (if we buy then inventory goes up by the volume of the rfq, and cash is reduced by volume x price, and the reverse if we sell)\n",
        "* onMarketClose: at the end of the day all the inventory is liquidated at end of day prices passed as argument, meaning that you need to change the cash by the value of the inventory and set inventory for all instruments to zero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d03782a1",
      "metadata": {
        "id": "d03782a1"
      },
      "outputs": [],
      "source": [
        "# Complete the class only where it is specified by YOUR CODE HERE. Leave other parts untouched\n",
        "# IMPORTANT: all inputs to the class are specified in the constructor, in the inputs of the methods, or internally\n",
        "# Do not reference variables outside the scope of the class\n",
        "from pandas.tseries.offsets import BDay\n",
        "from scipy.optimize import fsolve\n",
        "\n",
        "class AvellanedaStoikov():\n",
        "    def __init__(self, gamma, num_days_training = 100, end_time = pd.to_datetime(\"19:00:00\").time()):\n",
        "        # Constructor of the class\n",
        "        self.gamma = gamma\n",
        "        self.num_days_training = num_days_training\n",
        "        self.end_time = end_time\n",
        "\n",
        "    def copy(self):\n",
        "        return AvellanedaStoikov(self.gamma, self.num_days_training, self.end_time)\n",
        "\n",
        "    def _initAlgo(self, instrument_names):\n",
        "        # Helper method that initializes the state of the algorithm\n",
        "        self.cash = 0\n",
        "        self._initPipeline()\n",
        "        self._initInventory(instrument_names)\n",
        "\n",
        "    def _initInventory(self, instrument_names):\n",
        "        # Helper method to initialize to zero the inventory for each instrument\n",
        "        q_list = [0]*len(instrument_names)\n",
        "        self.inventory = dict(zip(instrument_names, q_list))\n",
        "\n",
        "    def _initPipeline(self):\n",
        "        # In this helper method you need to RECREATE the pipeline you have selected during the first part\n",
        "        # of the exercise. You have to store the pipeline in self.pipeline class variable at the end of the method\n",
        "        # YOUR CODE HERE\n",
        "\n",
        "    def _fractionOfDay(self, dt):\n",
        "        # Helper method to calculate fractions of days\n",
        "        return (dt.hour * 3600 + dt.minute * 60 + dt.second) / 86400\n",
        "\n",
        "    def _getVolatility(self, historical_df):\n",
        "        # Implement a function that calculates the volatility of differences in mid prices end of day\n",
        "        # First you need to find the last mid per day, then calculate differences and\n",
        "        # finally the standard deviation (volatility). The result is a dictionary instrument - volatility\n",
        "        # that is returned by the function\n",
        "        # YOUR CODE HERE\n",
        "        pass\n",
        "\n",
        "    def _getDerivativeModel(self, model, context, feature):\n",
        "        # Helper method to calculate the derivative of a model with respect to a feature\n",
        "        epsilon = 0.001\n",
        "        local_context = context.copy()\n",
        "        predict0 = model.predict_proba(local_context)[0][1]\n",
        "        local_context.at[context.index[0], feature] += epsilon\n",
        "        predict1 = model.predict_proba(local_context)[0][1]\n",
        "        return (predict1 - predict0) / epsilon\n",
        "\n",
        "    def beforeMarketOpen(self, training_df):\n",
        "        # This method is called every day before the market opens\n",
        "        self._initAlgo(training_df[\"instrument\"].unique())\n",
        "        # Truncate the training_df to the number of days you will use (specified in class variable\n",
        "        # self.num_days_training), select the features and target to train your model, and call the fit\n",
        "        # function of your model\n",
        "        # YOUR CODE HERE\n",
        "        # ****\n",
        "        # END OF YOUR CODE\n",
        "        # Additionally, we calculate the volatility for each instrument\n",
        "        self.volatility = self._getVolatility(training_df)\n",
        "\n",
        "    def _pricingFormula(self, side, time, inventory, volatility, volume, prob, prob_der):\n",
        "        # evaluate the Avellaneda Stoikov formula given the inputs USING THE FORMUKA PROVIDED ABOVE\n",
        "        # We recommend to handle cases where the formula might not work well, e.g. with derivatives close to zero\n",
        "        # The function must return the Avellaneda - Stoikov SPREAD (not the price!)\n",
        "        # In order to compute the time difference (t-T) use the following helper function:\n",
        "        # self._fractionOfDay(time)\n",
        "        # self._fractionOfDay(self.end_time)\n",
        "        # YOUR CODE HERE\n",
        "        pass\n",
        "\n",
        "    def _iterPrice(self, rfq_model_df, spread):\n",
        "        # We use this helper function to calculate the inputs of the pricing formula\n",
        "        rfq_index = rfq_model_df.index[0]\n",
        "        rfq_model_df.at[rfq_index, \"spread\"] = spread\n",
        "        prob = self.pipeline.predict_proba(rfq_model_df)[0][1]\n",
        "        prob_der = self._getDerivativeModel(self.pipeline, rfq_model_df, \"spread\")\n",
        "        side = rfq_df.at[rfq_index, \"side\"]\n",
        "        time = rfq_df.at[rfq_index, \"time\"]\n",
        "        volume = rfq_df.at[rfq_index, \"vol(MM)\"]\n",
        "        instrument = rfq_df.at[rfq_index, \"instrument\"]\n",
        "        volatility = self.volatility[instrument]\n",
        "        inventory = self.inventory[instrument]\n",
        "        return self._pricingFormula(side, time, inventory, volatility, volume, prob, prob_der) - spread\n",
        "\n",
        "    def onRfQevent(self, rfq_df):\n",
        "        # In this code we take the rfq dataframe and calculate the optimal spread\n",
        "        # We use exceptions to capture issues in the calculation, in this case as a safety we quote conservatily\n",
        "        rfq_index = rfq_df.index[0]\n",
        "        f = lambda x: self._iterPrice(rfq_df, x)\n",
        "        try:\n",
        "            spread = fsolve(f, 0)[0]\n",
        "        except:\n",
        "            print(\"Error in the calculation, quoting conservatively\")\n",
        "            spread = 1000 # if any issue quote conservatively\n",
        "        return spread\n",
        "\n",
        "    def onTradeEvent(self, rfq_df, price):\n",
        "        # If there is a trade you must add or sustract (depending on side) the volume to the\n",
        "        # inventory of the instrument that has been closed\n",
        "        # To get propoerties from the dataframe, you can use the following code example:\n",
        "        # rfq_index = rfq_df.index[0]\n",
        "        # volume = rfq_df.at[rfq_index, \"vol(MM)\"]\n",
        "        # YOUR CODE HERE, recall that class variables are called with self.variable_name\n",
        "        # ****\n",
        "        # You also need to change the cash in the opposite direction and taking into account the price\n",
        "        # Prices of bonds are quoted in base 100, need to divide by 100 to convert to MM €\n",
        "        # YOUR CODE HERE\n",
        "        # ****\n",
        "\n",
        "    def onMarketClose(self, prices_dict):\n",
        "        # When the market closes, all the positions in the inventory are liquidated\n",
        "        # meaning that you need to convert them to cash using prices and set inventory to zero\n",
        "        # You should handle the possibility that no eod prices are available for the instrument\n",
        "        # using prices_dict.get(key, 0.0) in the incoming dictionary to retrieve value having a\n",
        "        # default 0.0\n",
        "        # Prices of bonds are quoted in base 100, need to divide by 100 to convert to MM €\n",
        "        # YOUR CODE HERE\n",
        "        # ****\n",
        "\n",
        "    def getCash(self):\n",
        "        return self.cash\n",
        "\n",
        "    def getInventory(self, instrument_name):\n",
        "        return self.inventory[instrument_name]\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d5eb2de",
      "metadata": {
        "id": "6d5eb2de"
      },
      "source": [
        "**Backtesting environment**\n",
        "\n",
        "The following code is a simple backtesting environment to run your market-making algorithm. Feel free to analyse the code but do not change the implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9f109d6",
      "metadata": {
        "id": "c9f109d6"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class BacktestingSession():\n",
        "    def __init__(self, algo, seed = 10):\n",
        "        self.algo = algo\n",
        "        random.seed(seed)\n",
        "\n",
        "    def _rfq_won(self, model, rfq, spread):\n",
        "        rfq_new_price = rfq.copy()\n",
        "        rfq_index = rfq_new_price.index[0]\n",
        "        rfq_new_price.at[rfq_index, \"spread\"] = spread\n",
        "        prob = model.predict_proba(rfq_new_price)[0][1]\n",
        "        return prob > random.random()\n",
        "\n",
        "    def _get_eod_prices(self, rfq_df):\n",
        "        return rfq_df[[\"instrument\", \"mid\"]].groupby(\"instrument\").last()[\"mid\"].to_dict()\n",
        "\n",
        "    def run_backtest(self, backtest_df, backtest_days):\n",
        "        required_columns = set([\"instrument\", \"client\", \"mid\", \"vol(MM)\", \"dv01\", \"num_dealers\", \"side\", \"date\", \"time\", \"periodOfDay\"])\n",
        "        if not required_columns.issubset(backtest_df.columns):\n",
        "            return \"Invalid backtest dataframe. Review that the required input columns are present\"\n",
        "        profit_and_loss = []\n",
        "        columns_results = [\"rfq_id\", \"price_algo\", \"spread_algo\", \"won_algo\", \"inventory_algo\"]\n",
        "        algo_results_df = pd.DataFrame(columns = columns_results)\n",
        "        # loop over dates\n",
        "        for date in backtest_days:\n",
        "            # initialize algo before the market opens\n",
        "            historical_df = backtest_df[backtest_df[\"date\"] < date]\n",
        "            self.algo.beforeMarketOpen(historical_df)\n",
        "            # loop over all rfqs of the day\n",
        "            single_day_df = backtest_df[backtest_df[\"date\"] == date]\n",
        "            rfq_id, prices_algo, spreads_algo, inv_algo, won_algo = [], [],[],[],[]\n",
        "            for index, _ in single_day_df.iterrows():\n",
        "                rfq_id.append(int(index))\n",
        "                rfq = single_day_df[single_day_df.index == index]\n",
        "                # get a spread quote from the algo\n",
        "                spread = self.algo.onRfQevent(rfq)\n",
        "                spreads_algo.append(spread)\n",
        "                instrument_name = rfq_df.at[index, \"instrument\"]\n",
        "                inv_algo.append(self.algo.getInventory(instrument_name))\n",
        "                mid = rfq_df.at[index, \"mid\"]\n",
        "                side = rfq_df.at[index, \"side\"]\n",
        "                price = mid - side * spread\n",
        "                prices_algo.append(price)\n",
        "                # simulate the result of the RfQ using the model from the algo\n",
        "                rfq_was_won = self._rfq_won(self.algo.pipeline, rfq, spread)\n",
        "                won_algo.append(int(rfq_was_won))\n",
        "                if rfq_was_won:\n",
        "                    self.algo.onTradeEvent(rfq, price)\n",
        "            # end of day we force the algo to liquidate the inventory at eod prices (no market impact)\n",
        "            eod_prices = self._get_eod_prices(single_day_df)\n",
        "            self.algo.onMarketClose(eod_prices)\n",
        "            profit_and_loss.append(self.algo.getCash())\n",
        "            results_day_df = pd.DataFrame({\"rfq_id\": rfq_id, \"price_algo\": prices_algo, \"spread_algo\": spreads_algo, \\\n",
        "                                        \"won_algo\": won_algo, \"inventory_algo\": inv_algo})\n",
        "            algo_results_df = pd.concat([algo_results_df, results_day_df])\n",
        "        # wrap up results\n",
        "        pl_df = pd.DataFrame({\"date\": backtest_days, \"P&L\": profit_and_loss})\n",
        "        test_set = backtest_df[backtest_df[\"date\"].isin(backtest_dates)]\n",
        "        rfq_results_df = test_set.join(algo_results_df.set_index(\"rfq_id\"))\n",
        "        return pl_df, rfq_results_df\n",
        "\n",
        "    def run_pl_backtest_gamma(self, backtest_df, backtest_days, gamma_list):\n",
        "        pl_results_df = None\n",
        "        rfq_df_list = []\n",
        "        for gamma in gamma_list:\n",
        "            print(gamma)\n",
        "            gamma_algo = self.algo.copy()\n",
        "            gamma_algo.gamma = gamma\n",
        "            gamma_backtest = BacktestingSession(gamma_algo)\n",
        "            pl_df, rfq_df = gamma_backtest.run_backtest(backtest_df, backtest_days)\n",
        "            pl_df = pl_df.rename(columns = {\"P&L\": str(gamma)})\n",
        "            if pl_results_df is None:\n",
        "                pl_results_df = pl_df\n",
        "            else:\n",
        "                pl_results_df = pd.merge(pl_results_df, pl_df, on = \"date\", how = \"left\")\n",
        "            rfq_df_list.append(rfq_df)\n",
        "        return pl_results_df, rfq_df_list"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15a09c29",
      "metadata": {
        "id": "15a09c29"
      },
      "source": [
        "**Backtesting of the trading algorithm**\n",
        "\n",
        "Now you will use a backtesting utility to analyze the performance of your trading algorithm. As a performance metric we will use the profit & loss (P&L) distribution at the end of the day. This is computed by keeping track of a cash account that is 0 at the beginning of the day (we consider we can borrow money at 0% interest rate). When we buy an instrument, the cash account decreases $-p_{a,i} * v_i$, whereas when we sell we add $p_{b_i} * v_i$. If the algorithm has any residual inventory at the end of the day, we assume it can be sold (if long) or bought (if short) at the closing mid-price (which is an optimistic hypothesis). Therefore, the cash account at then end of the day reflects the profit or loss of that day.\n",
        "\n",
        "At the core of the backtesting engine is the simulation of the RfQ result. We cannot use the historical result, since in backtesting we will be likely quoting a different price than the one quoted in the historical dataset. In this exercise, we will use the same model you have built for the probability of winning the RfQ to decide the result of the process, that is encapsulated in the Avellaneda Stoikov class. Bear in mind that this is a quite optimistic assumption, since in reality our model will be only an approximation (in the best scenario) of the actual behavior of investors! To simulate the process, for every price quoted, the backtesting engine calculates the probability of winning the RfQ with the model and generate a random uniform variabe between 0 and 1. If the random variable is lower than the probability, the RfQ is won.\n",
        "\n",
        "Perform the following analysis:\n",
        "* Run the backtesting over the same test set you selected to assess the probability of winning the RfQ model. The backtesting session needs and instance of the algo to be initialized. To run a backtesting,  you need to pass all the rfqs (train plus test) as a dataframe with at least the columns: instrument, client, mid, vol(MM), dv01, num_dealers, side, date, time, periodOfDay + a numerical index for each rfq (this can just be the index assigned by Pandas to each row). Additionally, you need to pass a list of dates over which testing will be done (i.e. the dates of your test set)\n",
        "\n",
        "* The backtesting returns two dataframes: one with the profit&loss for each day of the backtesting period, and an enriched test set with additional columns related to the outputs of the simulation, with columns:\n",
        "    * spread_algo: the spread quoted by the trading algorithm for the given RfQ\n",
        "    * price_algo: the price quoted by the trading algorithm for the given RfQ (mid + side * spread)\n",
        "    * won_algo: if the trading algorithm won the RfQ in the simulation (as in the training set, 1 = won, 0 = miss)\n",
        "    * inventory_algo: the inventory of the algo before quoting the RfQ, in the instrument being quoted (since we have multiple instruments, the algo keeps and inventory of each instrument separately)\n",
        "\n",
        "* Plot the distribution of daily P&L for the algorithm and different values of the risk-aversion. Compute the mean, standard deviation, Sharpe ratio and the maximum drawdown using the backtesting results. For the latter you need to calculate the accumulated return of the strategy over the backtesting period: assume you start with initial holdings \"1\" and compound the daily return over this initial holding (e.g. if the first day the strategy generates 3%, then end of day the holdings are 1.03, if second day is -2%, then you have 1.0094, and so on).\n",
        "\n",
        "* Calculate the distribution of the daily hit&miss (H&M), which is the ratio between rfqs won and total rfqs. Do you see any correlation between hit & miss and P&L.\n",
        "\n",
        "* Rerun the analysis using different values of gamma in a logarithmic scale. You can use the utility provided in the backtesting framework. Compare the statistics (P&L, H&M) from the previous point for the different values of gamma. How do you think the risk aversion affects the P&L distribution? And the H&M?\n",
        "    \n",
        "    [Optional] Analyze the limit cases of zero and infinite risk aversion in the Avellaneda - Stoikov formula and interpret the results\n",
        "    \n",
        "    [Optional] If you enjoy mathematics, you can derive the target H&M of the model using a simple model for the probability of winning the RfQ. Assume $P(win|\\delta) \\equiv P(\\delta) = exp(-\\alpha \\delta)$, and plug it in the Avellaneda - Stoikov formulae. You will see that the formulae simplify and you have a closed-form for the spread. The target hit & miss corresponds to evaluationg $P(\\delta)$ with the optimal spread you just derived. Analyze the result and dependencies with respect to the parameters.\n",
        "\n",
        "* Picking one particular gamma, analyze days where the algorithm performs the best, the worse, and average. Looking at the behaviour of the algo during the day for the different instruments, try to explain the reason of the good / bad / average performance. Support your discussions with plots if needed (evolution of inventory levels, spreads, mids, etc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3988b88e",
      "metadata": {
        "id": "3988b88e"
      },
      "outputs": [],
      "source": [
        "## Example running code\n",
        "## rfq_df is the full dataset of rfqs, backtest_dates is a list of test dates (a subset of the dates in rfq_df)\n",
        "# algo = AvellanedaStoikov(gamma = 0.01)\n",
        "# backtesting = BacktestingSession(algo)\n",
        "# pl_result_df, rfq_result_df = backtesting.run_backtest(rfq_df, backtest_dates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93598a16",
      "metadata": {
        "id": "93598a16"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}